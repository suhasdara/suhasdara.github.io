<!DOCTYPE html><html lang="en" class="dark"> <head><meta charset="UTF-8"><meta name="description" content="Suhas Dara's Portfolio"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg?v=1"><link rel="shortcut icon" href="/favicon.svg?v=1"><link rel="alternate" type="application/rss+xml" title="Suhas Dara - Blog" href="/rss.xml"><title>Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos - Suhas Dara</title><link rel="stylesheet" href="/_astro/about.BYTpvR0z.css">
<style>.code-block-wrapper[data-astro-cid-jgrc2lfe] pre[data-astro-cid-jgrc2lfe]{margin-top:0!important;border-top-left-radius:0!important;border-top-right-radius:0!important}.code-block-header[data-astro-cid-jgrc2lfe]{font-family:ui-monospace,SFMono-Regular,SF Mono,Consolas,Liberation Mono,Menlo,monospace}
</style></head> <body class="bg-black text-green-400 min-h-screen font-mono"> <nav class="bg-gray-900 border-b border-green-600/30 shadow-lg shadow-green-500/10"> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex justify-between h-16"> <div class="flex items-center space-x-8"> <a href="/" class="text-green-400 font-bold text-xl tracking-wider"> <span class="text-green-600">$</span> suhas<span class="text-green-600">@</span>portfolio
</a> <div class="hidden md:flex space-x-1"> <a href="/about" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 px-3 py-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200">~/about</a> <a href="/projects" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 px-3 py-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200">~/projects</a> <a href="/experience" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 px-3 py-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200">~/experience</a> <a href="/blogs" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 px-3 py-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200">~/blogs</a> </div> </div> <!-- Mobile menu button --> <div class="md:hidden flex items-center"> <button id="mobile-menu-button" class="text-green-300 hover:text-green-400 focus:outline-none focus:text-green-400 border border-green-400/30 rounded p-1" aria-label="Toggle menu"> <svg xmlns="http://www.w3.org/2000/svg" stroke-width="2" width="20" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" fill="none" viewBox="0 0 24 24" id="menu-icon" class="lucide lucide-menu">  <path d="M4 12h16"></path> <path d="M4 18h16"></path> <path d="M4 6h16"></path>  </svg> <svg xmlns="http://www.w3.org/2000/svg" stroke-width="2" width="20" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" fill="none" viewBox="0 0 24 24" id="close-icon" class="lucide lucide-x hidden">  <path d="M18 6 6 18"></path> <path d="m6 6 12 12"></path>  </svg> </button> </div> </div> <!-- Mobile menu --> <div id="mobile-menu" class="md:hidden overflow-hidden transition-all duration-300 ease-in-out max-h-0"> <div class="px-2 pt-2 pb-3 space-y-1 bg-gray-800 border-t border-green-600/30"> <a href="/about" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 block px-3 py-2 rounded border border-transparent hover:border-green-400/30 transform transition-all duration-200 translate-y-2 opacity-0 menu-item">~/about</a> <a href="/projects" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 block px-3 py-2 rounded border border-transparent hover:border-green-400/30 transform transition-all duration-200 translate-y-2 opacity-0 menu-item" style="transition-delay: 50ms;">~/projects</a> <a href="/experience" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 block px-3 py-2 rounded border border-transparent hover:border-green-400/30 transform transition-all duration-200 translate-y-2 opacity-0 menu-item" style="transition-delay: 100ms;">~/experience</a> <a href="/blogs" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 block px-3 py-2 rounded border border-transparent hover:border-green-400/30 transform transition-all duration-200 translate-y-2 opacity-0 menu-item" style="transition-delay: 150ms;">~/blogs</a> </div> </div> </div> </nav> <main class="max-w-7xl mx-auto py-6 px-4 sm:px-6 lg:px-8">  <article class="max-w-4xl mx-auto"> <div class="mb-8"> <a href="/projects" class="text-blue-400 hover:text-blue-300 mb-4 inline-block">
← Back to Projects
</a> <h1 class="text-4xl font-bold mb-4">Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos</h1> <div class="flex flex-wrap gap-4 text-sm text-gray-400 mb-6"> <span> Oct 2020 -
Dec 2020 </span> <a href="https://github.com/suhasdara/Deepfake-Detection" target="_blank" rel="noopener noreferrer" class="text-blue-400 hover:text-blue-300">
View Repository →
</a>  <a href="/static/deepfake_paper.pdf" target="_blank" rel="noopener noreferrer" class="text-blue-400 hover:text-blue-300">
Research Paper →
</a> </div> </div> <div class="mb-8"> <img src="/projects/2020-12-08-Deepfake/featured.png" alt="Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos" data-title="Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos" class="modal-image w-full max-w-2xl max-h-96 mx-auto rounded-lg shadow-lg object-contain hover:shadow-xl transition-shadow"> </div> <div class="grid md:grid-cols-3 gap-8 mb-8"> <div class="md:col-span-2"> <div class="prose prose-invert prose-blue max-w-none"> <p>This project was an effort to determine whether a crowd has the ability to
distinguish Deepfake images and videos from real images and videos. This was
submitted for the final project as part of the
<a href="https://www.ischool.utexas.edu/~ml/teaching/crowd-fall20">CS395T</a> Human
Computation and Crowdsourcing course at UT Austin.</p>
<h3 id="background">Background</h3>
<p>In the modern era where Machine Learning (ML) and Artificial Intelligence (AI)
are taking over a lot of fields, we tend to forget the large amounts of data
that is involved in training these algorithms. To top it off, a huge portion
of the algorithms require supervised learning where the data needs to be
labeled with the correct output the algorithm needs to learn. With millions or
billions of data samples to solve a single problem, data labeling has become a
tedious task.</p>
<p>Over the years, a new way to fulfill data labeling needs took shape. Called
“Crowdsourcing”, this new method involved outsourcing the data labeling work
to other people who are willing to do such repetitive work for some amount of
money per data sample labeled. However, considering humans have a tendency to
be erroneous and sometimes even malicious, crowdsourcing has become a field of
study in itself. This includes understanding human behavior, learning what
tasks humans are good at, learning how to maximize the output quality and
quantity, how to curb mal-intent, and a lot of other areas.</p>
<p>A lot of platforms became quite large since the concept of crowdsourcing
became popular, and for some people, these platforms became a main source of
income. These platforms allow <strong>requesters</strong> to create Human Intelligence
Tasks (HITs) that the <strong>workers</strong> could then work on and earn money. The
largest single platform for crowdsourcing is
<a href="https://www.mturk.com/">Amazon Mechanical Turk (MTurk)</a>, which was launched
in 2005. More recently, the popularity further increased when Amazon Web
Services (AWS) released the SageMaker platform in 2017, which is a cloud
machine-learning platform. SageMaker introduced a requester-friendly interface
wrapping around MTurk called
<a href="https://aws.amazon.com/sagemaker/groundtruth/">Ground Truth (GT)</a> to design
and generate HITs for recording worker responses that directly could be
integrated with machine-learning algorithms.</p>
<h3 id="our-project">Our Project</h3>
<p>One of the growing problems due to the Internet age is misinformation. This
happens when false information is shared with network circles through social
media whether intentionally or unintentionally. Due to increasingly strong
artificial intelligence, we now have the capability to create <strong>Deepfakes</strong>.
Deepfakes are artificially created media (images or videos) that look like
real humans. The Deepfake could be of a real person (as you can see in the
Obama Deepfake image above), or it could just be a person who does not exist
and is a mere combination of facial features from several real people.
Deepfakes can be strong propagators of disinformation (intentional
misinformation) because of how easy it is becoming to get access to a deep
learning model that can generate Deepfakes.</p>
<p>There is currently ongoing research to create models that can detect Deepfakes
including an ongoing challenge by Facebook AI to understand the progress on
Deepfake detection technology that uses the Facebook DeepFake Detection
Challenge Dataset (DFDC). However, the problem exists that training a model
to be good would require large amounts of labeled data. We decided to tackle
the question of whether the crowd is good at differentiating Deepfakes from
real media, and especially does it make a difference if the media is an image
versus a video.</p>
<p>We chose certain datasets to source Deepfake images, Deepfake videos, real
images, and real videos. Funnily enough, we used the DFDC dataset to get
the labeled video samples to understand whether humans are good at labeling
these video samples correctly (a chicken and egg problem). We created HITs
using SageMaker GT that thoroughly explained what exactly are Deepfakes and
what we expect from the workers. We used past research knowledge to design
the HITs to be somewhat resistant to malicious intentions while also providing
us with good results to analyze.</p>
<p>We designed the HIT such that each worker would analyze two images and two
videos (not necessarily one each of Deepfake and real media) by not only
labeling whether a media is Deepfake or not, but also providing a reasoning
of how they reached their judgment. Additionally, each worker also
completed a survey that collected demographic information (age, race, gender)
and cognitive level information (through
<a href="https://en.wikipedia.org/wiki/Cognitive_reflection_test">CRT questions</a>).
As we were trying to understand if the crowd as a whole is capable of
detecting Deepfakes and not necessarily individuals, each media was analyzed
by five different workers.</p>
<p>Through this experiment, we wanted to analyze a few different aspects of
human intelligence to label Deepfakes:</p>
<ol>
<li>Does the crowd detect deepfaked videos better than deepfaked images?</li>
<li>Does the crowd reason differently for images and videos?</li>
<li>What features does the crowd use to aid in Deepfake detection?</li>
<li>What demographic of crowd has the highest accuracy?</li>
<li>Does performing well on a CRT test imply a higher accuracy at identifying
Deepfakes?</li>
</ol>
<p>Overall, we came to an understanding that the crowd is generally better at
detecting deepfaked videos than images. We understood that this is likely
because of motion information also being available when watching videos as
compared to a still image. We discovered that generally for images, the crowd
did not have any features that really stood out, but for videos, the motion
features really helped differentiate Deepfakes from real media. Additionally,
we were not able to get conclusive results based on the demographic features
and CRT results because of our small sample size and heavily biased
demographics (e.g. 93% of our samples were labeled by men).</p>
<p>So while it is technically possible to use a crowd to label Deepfake media
(mostly videos), it is probably better with a much larger crowd and much
higher redundancy, and with good guidelines outlining the target features to
help distinguish Deepfakes from real media.</p>
<p>This is a concise overview of the results described in our paper, so you can
read our paper to get more insight and explanation for our results!</p> </div> </div> <div class="space-y-6 sticky top-6 self-start"> <div class="bg-gray-800 rounded-lg p-6"> <h3 class="text-lg font-semibold mb-4">Languages</h3> <div class="flex flex-wrap gap-2"> <span class="bg-blue-600 text-white px-3 py-1 rounded text-sm">Python</span> </div> </div> <div class="bg-gray-800 rounded-lg p-6"> <h3 class="text-lg font-semibold mb-4">Tools & Technologies</h3> <div class="flex flex-wrap gap-2"> <span class="bg-gray-700 text-gray-300 px-3 py-1 rounded text-sm">Amazon Sagemaker Ground Truth</span><span class="bg-gray-700 text-gray-300 px-3 py-1 rounded text-sm">Pandas</span><span class="bg-gray-700 text-gray-300 px-3 py-1 rounded text-sm">NumPy</span><span class="bg-gray-700 text-gray-300 px-3 py-1 rounded text-sm">Matplotlib</span> </div> </div> <div class="bg-gray-800 rounded-lg p-6"> <h3 class="text-lg font-semibold mb-4">Team</h3> <div class="space-y-2"> <div class="text-gray-300">Aditya Tyagi</div> </div> </div> </div> </div> </article> <script type="module">function i(){document.querySelectorAll("pre code").forEach(o=>{const t=o.parentElement;if(!t||t.tagName!=="PRE"||t.querySelector(".copy-button"))return;let a="text";if(o.className){let e=o.className.match(/language-(\w+)/);e?a=e[1]:(e=o.className.match(/(\w+)/),e&&!["hljs","shiki","astro-code"].includes(e[1])&&(a=e[1]))}if(a==="text"&&t.className){let e=t.className.match(/language-(\w+)/);e?a=e[1]:(e=t.className.match(/astro-code-(\w+)/),e&&(a=e[1]))}if(a==="text"){const e=t.getAttribute("data-language")||o.getAttribute("data-language");e&&(a=e)}if(a==="text"){const e=o.textContent||"";e.includes("def ")||e.includes("import ")||e.includes("print(")?a="python":e.includes("function ")||e.includes("const ")||e.includes("console.log")?a="javascript":(e.includes("SELECT ")||e.includes("FROM "))&&(a="sql")}console.log("Code block detected:",{codeClass:o.className,preClass:t.className,detectedLanguage:a,preAttributes:Array.from(t.attributes).map(e=>`${e.name}="${e.value}"`),codeAttributes:Array.from(o.attributes).map(e=>`${e.name}="${e.value}"`)});const r=document.createElement("div");r.className="code-block-wrapper relative",t.parentNode?.insertBefore(r,t),r.appendChild(t);const l=document.createElement("div");l.className="code-block-header flex justify-between items-center bg-gray-800 px-4 py-2 rounded-t-lg border-b border-gray-700";const d=document.createElement("span");d.className="text-sm text-gray-400 font-mono uppercase",d.textContent=a;const s=document.createElement("button");s.className="copy-button text-sm text-gray-400 hover:text-white transition-colors px-3 py-1 rounded bg-gray-700 hover:bg-gray-600 flex items-center gap-2",s.innerHTML=`
        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
          <rect width="14" height="14" x="8" y="8" rx="2" ry="2"/>
          <path d="m4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"/>
        </svg>
        <span class="copy-text">Copy</span>
        <span class="copied-text hidden">Copied!</span>
      `,s.addEventListener("click",async()=>{try{const e=o.textContent||"";await navigator.clipboard.writeText(e);const n=s.querySelector(".copy-text"),c=s.querySelector(".copied-text");n&&c&&(n.classList.add("hidden"),c.classList.remove("hidden"),setTimeout(()=>{n.classList.remove("hidden"),c.classList.add("hidden")},2e3))}catch(e){console.error("Failed to copy code:",e);try{const n=document.createElement("textarea");n.value=o.textContent||"",document.body.appendChild(n),n.select();const c=document.execCommand("copy");if(document.body.removeChild(n),!c)throw new Error("execCommand failed")}catch(n){console.error("Clipboard fallback also failed:",n)}}}),l.appendChild(d),l.appendChild(s),r.insertBefore(l,t),t.style.marginTop="0",t.style.borderTopLeftRadius="0",t.style.borderTopRightRadius="0"})}document.addEventListener("DOMContentLoaded",i);document.addEventListener("astro:page-load",i);</script>   </main> <footer class="bg-gray-900 border-t border-green-600/30 py-8 mt-16"> <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"> <div class="flex flex-col sm:flex-row justify-between items-center gap-4"> <p class="text-green-300 font-mono text-sm"> <span class="text-green-600">#</span> &copy; 2025 Suhas Dara. All rights reserved.
</p> <div class="flex items-center gap-4"> <a href="https://www.linkedin.com/in/suhas-dara" target="_blank" rel="noopener noreferrer" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 p-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200" aria-label="LinkedIn"> <svg xmlns="http://www.w3.org/2000/svg" stroke-width="2" width="18" height="18" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" fill="none" viewBox="0 0 24 24" class="lucide lucide-linkedin">  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path> <rect width="4" height="12" x="2" y="9"></rect> <circle cx="4" cy="4" r="2"></circle>  </svg> </a> <a href="https://www.github.com/suhasdara" target="_blank" rel="noopener noreferrer" class="text-green-300 hover:text-green-400 hover:bg-green-400/10 p-2 rounded border border-transparent hover:border-green-400/30 transition-all duration-200" aria-label="GitHub"> <svg xmlns="http://www.w3.org/2000/svg" stroke-width="2" width="18" height="18" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" fill="none" viewBox="0 0 24 24" class="lucide lucide-github">  <path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path> <path d="M9 18c-4.51 2-5-2-7-2"></path>  </svg> </a> </div> </div> </div> </footer> <!-- Image Modal --><div id="imageModal" class="fixed inset-0 bg-black/80 backdrop-blur-sm flex items-center justify-center z-50 hidden p-4"> <div class="relative w-full h-full max-w-6xl max-h-full flex items-center justify-center"> <img id="modalImage" src="" alt="" class="max-w-full max-h-full object-contain rounded-lg shadow-2xl"> <button id="modalCloseButton" class="absolute top-4 right-4 bg-black/50 hover:bg-black/70 text-white rounded-full p-2 transition-colors z-10" aria-label="Close modal"> <svg xmlns="http://www.w3.org/2000/svg" stroke-width="2" width="24" height="24" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" fill="none" viewBox="0 0 24 24" class="lucide lucide-x">  <path d="M18 6 6 18"></path> <path d="m6 6 12 12"></path>  </svg> </button> <div id="modalCaption" class="absolute bottom-4 left-4 right-4 text-center z-10"> <p class="bg-black/50 text-white px-4 py-2 rounded-lg text-lg font-medium"></p> </div> </div> </div> <script type="module">function i(d,c,t){const e=document.getElementById("imageModal"),o=document.getElementById("modalImage"),a=document.getElementById("modalCaption");o&&(o.src=d,o.alt=c||"");const n=a?.querySelector("p");n&&(n.textContent=t||c||""),e?.classList.remove("hidden"),document.body.style.overflow="hidden"}function s(){document.getElementById("imageModal")?.classList.add("hidden"),document.body.style.overflow="auto"}function m(){const d=document.getElementById("imageModal"),c=document.getElementById("modalCloseButton");d&&(c?.addEventListener("click",s),d.addEventListener("click",function(t){t.target===this&&s()}),document.addEventListener("keydown",function(t){t.key==="Escape"&&!d.classList.contains("hidden")&&s()}),document.querySelectorAll(".modal-image").forEach(t=>{const e=t;e.style.cursor="pointer",t.addEventListener("click",o=>{o.preventDefault(),o.stopPropagation();const a=e.src,n=e.alt,l=e.getAttribute("data-title")||n;i(a,n,l)})}),document.querySelectorAll(".prose img").forEach(t=>{const e=t;e.style.cursor="pointer",t.classList.add("hover:shadow-lg","transition-shadow"),t.addEventListener("click",o=>{o.preventDefault(),o.stopPropagation();const a=e.src,n=e.alt,l=e.getAttribute("data-title")||n||"Image";i(a,n,l)})}))}document.addEventListener("DOMContentLoaded",m);document.addEventListener("astro:page-load",m);</script> <script type="module">function c(){const l=document.getElementById("mobile-menu-button"),e=document.getElementById("mobile-menu"),o=document.getElementById("menu-icon"),i=document.getElementById("close-icon");if(!l||!e||!o||!i)return;l.addEventListener("click",()=>{const a=e.style.maxHeight&&e.style.maxHeight!=="0px",s=e.querySelectorAll(".menu-item");a?(s.forEach((t,n)=>{setTimeout(()=>{t.classList.add("translate-y-2","opacity-0"),t.classList.remove("translate-y-0","opacity-100")},n*30)}),setTimeout(()=>{e.style.maxHeight="0px",o.classList.remove("hidden"),i.classList.add("hidden")},s.length*30+100)):(e.style.maxHeight=e.scrollHeight+"px",o.classList.add("hidden"),i.classList.remove("hidden"),s.forEach((t,n)=>{setTimeout(()=>{t.classList.remove("translate-y-2","opacity-0"),t.classList.add("translate-y-0","opacity-100")},n*50)}))}),e.querySelectorAll("a").forEach(a=>{a.addEventListener("click",()=>{const s=e.querySelectorAll(".menu-item");s.forEach((t,n)=>{setTimeout(()=>{t.classList.add("translate-y-2","opacity-0"),t.classList.remove("translate-y-0","opacity-100")},n*30)}),setTimeout(()=>{e.style.maxHeight="0px",o.classList.remove("hidden"),i.classList.add("hidden")},s.length*30+100)})})}document.addEventListener("DOMContentLoaded",c);document.addEventListener("astro:page-load",c);</script> </body> </html>