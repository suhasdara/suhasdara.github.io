{
    "componentChunkName": "component---src-templates-project-temp-js",
    "path": "/projects/lstm-study",
    "result": {"data":{"mdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"A Replication Study to Assess the Ability of LSTMs to Learn Syntax-Sensitive Dependencies\",\n  \"startDates\": [\"2021-03-17T00:00:00.000Z\"],\n  \"endDates\": [\"2021-05-13T00:00:00.000Z\"],\n  \"team\": [\"Mofei Zhang\"],\n  \"languages\": [\"Python3\"],\n  \"tools\": [\"PyTorch\", \"NumPy\"],\n  \"slug\": \"/projects/lstm-study\",\n  \"repository\": \"https://github.com/mofeiZ/nlp_final_proj\",\n  \"paperSlug\": \"/lstm_paper.pdf\",\n  \"postType\": \"project\",\n  \"image\": \"featured.png\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This project was a study to replicate the results of a paper by Linzen et al.\\ntitled \\\"Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies\\\".\\nThis was submitted for the final project as part of the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.cs.utexas.edu/~gdurrett/courses/sp2021/cs388.shtml\"\n  }, \"CS388\"), \"\\nNatural Language Processing course at UT Austin. The original paper can be\\nfound\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00115/43378/Assessing-the-Ability-of-LSTMs-to-Learn-Syntax\"\n  }, \"here\"), \".\"), mdx(\"p\", null, \"Before I talk about the project, I would like to provide a small introduction\\nto Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks\\n(LSTMs).\"), mdx(\"h3\", null, \"What are RNNs?\"), mdx(\"p\", null, \"Recurrent Neural Networks use sequential data to solve temporal (time-based)\\nand ordinal (location-based) problems. This commonly includes natural\\nlanguage processing problems such as translation and prediction, and also\\naudio and video processing problems.\"), mdx(\"p\", null, \"Recurrent Neural Networks can be thought of as chain of cells where each\\ncell maps to a different word in a sentence, or a different frame in a video,\\netc. However, it is modeled using a single cell where the weights for the same\\ncell are updated in a loop. The weights of the RNN are refined through every\\ncell's output with the use of Backpropagation Through Time (BPTT), which\\nfactors in the error in the cell's prediction for each time step in the\\nnetwork's loop.\"), mdx(\"p\", null, \"However, RNNs can run into two similar problems: exploding gradients and\\nvanishing gradients. Exploding gradients occur when the backpropagated error\\nkeeps increasing exponentially because of large errors in the loop. Vanishing\\ngradients occur when the backpropagated error keeps decreasing exponentially\\nto zero because of very small errors in the loop. Both are problematic because\\none makes the model unstable while the other makes the model useless (zero\\nweights). These issues are more likely to arise when the inputs to the model\\nare very long.\"), mdx(\"p\", null, \"Different architectures including Long Short-Term Memory networks (LSTMs)\\nand Gated Recurrent Unit networks (GRUs) were introduced to combat these\\ngradient issues that arise with the use of simple RNNs.\"), mdx(\"h4\", null, \"What are LSTMs?\"), mdx(\"p\", null, \"LSTMs are a type of RNNs that can deal with long-term dependencies in the\\ninputs. If important context information to the current step in the\\nloop is not in the recent past, a simple RNN may lose the gradient and not\\nmake a good prediction.\"), mdx(\"p\", null, \"LSTMs introduce a new type of cell that has an input gate, an output gate,\\nand a forget gate. The forget gate is new functionality introduced to\\neliminate unimportant states from the network's overall cell state. This\\nallows more important context information to remain relevant over a\\nlong-term dependency in the input.\"), mdx(\"h3\", null, \"Our project\"), mdx(\"p\", null, \"As mentioned before, our project was to replicate the results of a paper\\nby Linzen et al. that demonstrates LSTMs can understand syntax-sensitive\\ndependencies. While this result lines up with the reasoning behind the use of\\nLSTMs, we wanted to verify their results and expand upon their ideas.\"), mdx(\"p\", null, \"The authors of the original paper implemented their models using an older\\nversion of Keras. However, being more familiar with the PyTorch library, a\\nmajor part of our paper replication project was to utilize\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/TalLinzen/rnn_agreement\"\n  }, \"their source code\"), \" to understand\\nwhat results were produced by what models and then translate the models into\\nPyTorch accordingly.\"), mdx(\"p\", null, \"The problem used to evaluate the ability of LSTMs to learn syntax structure\\nwas the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"Number Prediction Task\"), \". In this task, the model is supposed to\\npredict the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"number\"), \" (plurality) of the upcoming verb in  the sentence given\\nthe sentence up to and not including the verb. This may be a hard problem\\nbecause of several reasons outlined in our paper, including intervening nouns\\nand verbs.\"), mdx(\"p\", null, \"We used the dataset created by Linzen et al. to evaluate our models. We ran\\nseveral experiments including predicting the plurality of the verb by just\\nproviding the nouns leading up to the verb, just providing the POS (\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Part-of-speech_tagging\"\n  }, \"Part of\\nSpeech\"), \") tags of the\\nnouns leading up to the verb, and even providing the wrong labels to observe\\nif sentence context is being utilized.\"), mdx(\"p\", null, \"We also replicated a self-supervised learning model from the Linzen et al.\\npaper that uses just the previous words in the sentence to predict the next\\nword. No syntactic context is provided to the model directly i.e. the model\\ndoesn't explicitly know the plurality of the nouns and the verbs.\"), mdx(\"p\", null, \"In our paper replication study, we showed that our results majorly aligned\\nwith those of Linzen et al. However, we were not fully convinced that their\\nmethodology captured the full ability of LSTMs. So, we proposed two\\nextensions to their paper that can provide more insight into LSTMs. The\\nfirst extension was to randomize the subject in the sentence while keeping\\nthe verb the same. The second extension was to\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://nlp.stanford.edu/~johnhew/interpreting-probes.html\"\n  }, \"probe\"), \" our\\nnumber prediction model using a different task (POS tag prediction) to\\nunderstand whether the model was actually capturing syntax information. Our\\nresults suggested that the model was in fact capturing syntax and context\\ninformation.\"), mdx(\"p\", null, \"You can read our paper to get more insight and explanation for our results!\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"excerpt":"This project was a study to replicate the results of a paper by Linzen et al.\ntitled \"Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies\".\nThis was submitted for the final project..."},"frontmatter":{"title":"A Replication Study to Assess the Ability of LSTMs to Learn Syntax-Sensitive Dependencies","startDates":["2021-03-17T00:00:00.000Z"],"endDates":["2021-05-13T00:00:00.000Z"],"team":["Mofei Zhang"],"languages":["Python3"],"tools":["PyTorch","NumPy"],"slug":"/projects/lstm-study","repository":"https://github.com/mofeiZ/nlp_final_proj","paperSlug":"/lstm_paper.pdf","projectLink":null,"demoLink":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAAsTAAALEwEAmpwYAAADXUlEQVQ4y52U208bRxTG/d/mrVKlviBF6kvVqo3aNJCKUpJwUTCwxncbX7AdA2uvY6+NvV7WdrDBxEmBpkANjvFt91d5zSVUjQQ50tHMnjnz7flm5nwW7mmGYWDohjmXwznWH0lUpd3hirlm+SJAYwQofOtk9cEr4k8StPttM2b5b+JdfWg72RqhRzF2ctURhn5Z4VWSbuh39qHpDPhl4mda7dZ1UZZP/3hv+n2QxBR6X78BHAwG6AOdo7MDGs1d3jXrNJp7t/xzsfpJFW/MxdHpwfBOGGKZlHt0UNpJVF5T1FOUyFz7NmkKukT58vtqrCCj9lMsp2fJNUUMRlVa1kJr2DxLBCsuxLwXMevBp9pZVex4FRtrBSeptAd3bhnP1jLu7BLevIA7v4ynIGCNv8CeeclaPIRjxYFFUzViiQi5c5GIZCMYtyI3N0kdRpH+iiFWA/i9MyQPI0iHURIHEZKNMFbnJPboLD7FxkYjiFpRSCaSI8r/dI55i8bC5nMmfU84okaNAn9TZ6uV5OHUGG8pUUOhQYV6e4vA/B8EVl7glhcpdlJ87J/fvMOD0/dUjBypw5hJa7g5c7zOlH+caeFXNqM2tF6GN8YWoZKTn15+h0OYQqoEcCvL5JqbnLSOzYu5BSi+C+OUreyjYY0/x6MI2MV5QuuLVCkQKrtwyVbzbN3hWRK1IJ7CJ4BXFTZ7p2j9DEHxezayPyI3BHyhb9BO3IjbEwjerxDfzLGRf4w7PMafaAQqLjbfhwiVXCgXEh/7o8dt2a3tkconSX94xcr6OPO+HxDrLn5fHCNSWsKfmWZaeEisImCLj+NOPmUfFV/BhiO9wExokmjNy/aOSkkrY/H7/MxYn7GUmGHK/xS3skKw7GIls2g+H7/mxC4vmTF3wUbhIs0eRZOmI7uAIM0hvJ4jFA0wOzN7Iw7RYoDVop1diqitNOVuFu1CNt2ctzOUOjKFpkTuJIFylqLcyVHuZdlpqdftaLbe0IbUNU0z591ul16v97/e7/fNFhuOZqzbwxiMNHKgD7Do+qhl6nu7aGpxpCL6/cTC4EZgTMpn5y2e+SR+80gcfjgZgX6BPl4r9nZ1n6+nwzyY8CGpNXNxcFn5XVX86qhMwG6ng2Mjz0JEpnl2divpvqD/AiUE91757ilfAAAAAElFTkSuQmCC","aspectRatio":0.9318181818181818,"src":"/static/5061f257f6ce1b6fde56fdb473cba5dd/f006c/featured.png","srcSet":"/static/5061f257f6ce1b6fde56fdb473cba5dd/f006c/featured.png 246w","sizes":"(max-width: 246px) 100vw, 246px"}}}}}},"pageContext":{}},
    "staticQueryHashes": ["63159454"]}