{
    "componentChunkName": "component---src-templates-project-temp-js",
    "path": "/projects/deepfakes",
    "result": {"data":{"mdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos\",\n  \"startDates\": [\"2020-10-27T00:00:00.000Z\"],\n  \"endDates\": [\"2020-12-08T00:00:00.000Z\"],\n  \"team\": [\"Aditya Tyagi\"],\n  \"languages\": [\"Python3\"],\n  \"tools\": [\"Amazon Sagemaker Ground Truth\", \"Pandas\", \"NumPy\", \"Matplotlib\"],\n  \"slug\": \"/projects/deepfakes\",\n  \"repository\": \"https://github.com/suhasdara/Deepfake-Detection\",\n  \"paperSlug\": \"/deepfake_paper.pdf\",\n  \"postType\": \"project\",\n  \"image\": \"featured.png\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This project was an effort to determine whether a crowd has the ability to\\ndistinguish Deepfake images and videos from real images and videos. This was\\nsubmitted for the final project as part of the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.ischool.utexas.edu/~ml/teaching/crowd-fall20\"\n  }, \"CS395T\"), \" Human\\nComputation and Crowdsourcing course at UT Austin.\"), mdx(\"h3\", null, \"Background\"), mdx(\"p\", null, \"In the modern era where Machine Learning (ML) and Artificial Intelligence (AI)\\nare taking over a lot of fields, we tend to forget the large amounts of data\\nthat is involved in training these algorithms. To top it off, a huge portion\\nof the algorithms require supervised learning where the data needs to be\\nlabeled with the correct output the algorithm needs to learn. With millions or\\nbillions of data samples to solve a single problem, data labeling has become a\\ntedious task.\"), mdx(\"p\", null, \"Over the years, a new way to fulfill data labeling needs took shape. Called\\n\\\"Crowdsourcing\\\", this new method involved outsourcing the data labeling work\\nto other people who are willing to do such repetitive work for some amount of\\nmoney per data sample labeled. However, considering humans have a tendency to\\nbe erroneous and sometimes even malicious, crowdsourcing has become a field of\\nstudy in itself. This includes understanding human behavior, learning what\\ntasks humans are good at, learning how to maximize the output quality and\\nquantity, how to curb mal-intent, and a lot of other areas.\"), mdx(\"p\", null, \"A lot of platforms became quite large since the concept of crowdsourcing\\nbecame popular, and for some people, these platforms became a main source of\\nincome. These platforms allow \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"requesters\"), \" to create Human Intelligence\\nTasks (HITs) that the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"workers\"), \" could then work on and earn money. The\\nlargest single platform for crowdsourcing is\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.mturk.com/\"\n  }, \"Amazon Mechanical Turk (MTurk)\"), \", which was launched\\nin 2005. More recently, the popularity further increased when Amazon Web\\nServices (AWS) released the SageMaker platform in 2017, which is a cloud\\nmachine-learning platform. SageMaker introduced a requester-friendly interface\\nwrapping around MTurk called\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws.amazon.com/sagemaker/groundtruth/\"\n  }, \"Ground Truth (GT)\"), \" to design\\nand generate HITs for recording worker responses that directly could be\\nintegrated with machine-learning algorithms.\"), mdx(\"h3\", null, \"Our Project\"), mdx(\"p\", null, \"One of the growing problems due to the Internet age is misinformation. This\\nhappens when false information is shared with network circles through social\\nmedia whether intentionally or unintentionally. Due to increasingly strong\\nartificial intelligence, we now have the capability to create \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Deepfakes\"), \".\\nDeepfakes are artificially created media (images or videos) that look like\\nreal humans. The Deepfake could be of a real person (as you can see in the\\nObama Deepfake image above), or it could just be a person who does not exist\\nand is a mere combination of facial features from several real people.\\nDeepfakes can be strong propagators of disinformation (intentional\\nmisinformation) because of how easy it is becoming to get access to a deep\\nlearning model that can generate Deepfakes.\"), mdx(\"p\", null, \"There is currently ongoing research to create models that can detect Deepfakes\\nincluding an ongoing challenge by Facebook AI to understand the progress on\\nDeepfake detection technology that uses the Facebook DeepFake Detection\\nChallenge Dataset (DFDC). However, the problem exists that training a model\\nto be good would require large amounts of labeled data. We decided to tackle\\nthe question of whether the crowd is good at differentiating Deepfakes from\\nreal media, and especially does it make a difference if the media is an image\\nversus a video.\"), mdx(\"p\", null, \"We chose certain datasets to source Deepfake images, Deepfake videos, real\\nimages, and real videos. Funnily enough, we used the DFDC dataset to get\\nthe labeled video samples to understand whether humans are good at labeling\\nthese video samples correctly (a chicken and egg problem). We created HITs\\nusing SageMaker GT that thoroughly explained what exactly are Deepfakes and\\nwhat we expect from the workers. We used past research knowledge to design\\nthe HITs to be somewhat resistant to malicious intentions while also providing\\nus with good results to analyze.\"), mdx(\"p\", null, \"We designed the HIT such that each worker would analyze two images and two\\nvideos (not necessarily one each of Deepfake and real media) by not only\\nlabeling whether a media is Deepfake or not, but also providing a reasoning\\nof how they reached their judgment. Additionally, each worker also\\ncompleted a survey that collected demographic information (age, race, gender)\\nand cognitive level information (through\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://en.wikipedia.org/wiki/Cognitive_reflection_test\"\n  }, \"CRT questions\"), \").\\nAs we were trying to understand if the crowd as a whole is capable of\\ndetecting Deepfakes and not necessarily individuals, each media was analyzed\\nby five different workers.\"), mdx(\"p\", null, \"Through this experiment, we wanted to analyze a few different aspects of\\nhuman intelligence to label Deepfakes:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Does the crowd detect deepfaked videos better than deepfaked images?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Does the crowd reason differently for images and videos?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"What features does the crowd use to aid in Deepfake detection?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"What demographic of crowd has the highest accuracy?\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Does performing well on a CRT test imply a higher accuracy at identifying\\nDeepfakes?\")), mdx(\"p\", null, \"Overall, we came to an understanding that the crowd is generally better at\\ndetecting deepfaked videos than images. We understood that this is likely\\nbecause of motion information also being available when watching videos as\\ncompared to a still image. We discovered that generally for images, the crowd\\ndid not have any features that really stood out, but for videos, the motion\\nfeatures really helped differentiate Deepfakes from real media. Additionally,\\nwe were not able to get conclusive results based on the demographic features\\nand CRT results because of our small sample size and heavily biased\\ndemographics (e.g. 93% of our samples were labeled by men).\"), mdx(\"p\", null, \"So while it is technically possible to use a crowd to label Deepfake media\\n(mostly videos), it is probably better with a much larger crowd and much\\nhigher redundancy, and with good guidelines outlining the target features to\\nhelp distinguish Deepfakes from real media.\"), mdx(\"p\", null, \"This is a concise overview of the results described in our paper, so you can\\nread our paper to get more insight and explanation for our results!\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"excerpt":"This project was an effort to determine whether a crowd has the ability to\ndistinguish Deepfake images and videos from real images and videos. This was\nsubmitted for the final project as part of the..."},"frontmatter":{"title":"Determining Crowd’s Ability to Distinguish Deepfakes in Images and Videos","startDates":["2020-10-27T00:00:00.000Z"],"endDates":["2020-12-08T00:00:00.000Z"],"team":["Aditya Tyagi"],"languages":["Python3"],"tools":["Amazon Sagemaker Ground Truth","Pandas","NumPy","Matplotlib"],"slug":"/projects/deepfakes","repository":"https://github.com/suhasdara/Deepfake-Detection","paperSlug":"/deepfake_paper.pdf","projectLink":null,"demoLink":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACYklEQVQoz1XQ3U9SARzGcYZwDucQ4BtJpiAHOXhAQEjFl6YYvoBOnW9AM1PSks0S17tzc5bmdG615rKt3Oyii7qu7vK2q+ba2vp3vg3spovn6rfns2c/3UxPmJFElO3NefZf3GZ9LcNEj8p0n0J6QCU94GUq0YgkiZQZjFyQJS7aLJhlGVE0IQjCf9EVZpLsbdxibzfHm/UFfr1c53hliutJP9mhJjIDTUz2qciSCaNRoFdzsprs5FluhoVrMQRRRPyXErg6Pc7GnUF2tuZ5vTDF6YM8HxczLKV6mJ3qJ5ceIjMaR5akUqHb7WArneLz5hrbc2O4aqpLy02m87W6lKYynojy8vkCn5am+Za/ydelLIdLE9wvZLmRTTLY34kkmZAEgfGAwtOJIQ4W05w8XCbdFUGnLyuBYhFscbu52h5hOZdgJdXB4XCC3f5eRuNttMZaCLcECAa1Elgs9HqdFIb6KAwPcLA4S8TrQW8wnIOiiM7tVAj6/KgNdczNTPLhbp7HI8O0RaNomkoopOH3+5AkCaMgYC+30a64udefINXeir2qCqPRiKn4wyIYC0UIBaMoLi+FfIHfp2ec7L2jJRhB9fgIBYK0+gM4JBGLoYxqWSLaUE88HGKs6wpBpR6bZMZjteCQZXTNvmaam8K46hR2nmzy48tP3u4d09vejdbox+P24XW6cVitCIKIXq8ncMnOo/E427kxamtqsFgrKbdVUF1eha6h3oOmNuOsU3j/6oiz73842j+hIxLD41Kpq3XhcFymvKIam60Ss9mKIEpkBuMkOtowyVYqK+ylm9VWyV+Q9ijdZGwpGAAAAABJRU5ErkJggg==","aspectRatio":2.1666666666666665,"src":"/static/efd2ebe7d4cc01e7c0efe521ecaa295b/81944/featured.png","srcSet":"/static/efd2ebe7d4cc01e7c0efe521ecaa295b/ce452/featured.png 325w,\n/static/efd2ebe7d4cc01e7c0efe521ecaa295b/b50f6/featured.png 650w,\n/static/efd2ebe7d4cc01e7c0efe521ecaa295b/81944/featured.png 875w","sizes":"(max-width: 875px) 100vw, 875px"}}}}}},"pageContext":{}},
    "staticQueryHashes": ["63159454"]}